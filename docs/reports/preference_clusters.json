{
  "generated_at": "2025-11-11T03:15:24+00:00",
  "preference_label": "like",
  "min_cluster_size": 4,
  "min_samples": 2,
  "cluster_dim": 50,
  "cluster_n_neighbors": 40,
  "cluster_metric": "cosine",
  "viz_n_neighbors": 20,
  "sample_size": 5,
  "total_points": 152,
  "noise_count": 27,
  "cluster_persistence": [
    0.10955788127496019,
    0.0,
    0.3485998508370121,
    0.37661814886203576,
    0.14113258544113572,
    0.019270069581129243,
    0.17039045907615236,
    0.2084875305868414,
    0.007598704302121913,
    0.04121029829536037,
    0.3171430465604507,
    0.0002350427345355639,
    0.11156080113016417,
    0.21634311382272103,
    0.24410764762586593
  ],
  "plot_path": "docs/images/preference_clusters.png",
  "report_path": "docs/reports/preference_clusters.json",
  "clusters": [
    {
      "label": 0,
      "size": 5,
      "mean_probability": 0.9649831618207869,
      "top_categories": [
        "cs.LG",
        "cs.CL",
        "cs.AI",
        "stat.ML"
      ],
      "representative_ids": [
        "2410.18779",
        "2402.15613",
        "2406.07515",
        "2504.15208",
        "2503.00808"
      ],
      "samples": [
        {
          "id": "2410.18779",
          "title": "A Little Help Goes a Long Way: Efficient LLM Training by Leveraging\n  Small LMs",
          "summary": "A primary challenge in large language model (LLM) development is their onerous pre-training cost. Typically, such pre-training involves optimizing a self-supervised objective (such as next-token prediction) over a large corpus. This paper e…",
          "categories": [
            "cs.LG",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2402.15613",
          "title": "Towards Efficient Active Learning in NLP via Pretrained Representations",
          "summary": "Fine-tuning Large Language Models (LLMs) is now a common approach for text classification in a wide range of applications. When labeled documents are scarce, active learning helps save annotation efforts but requires retraining of massive m…",
          "categories": [
            "cs.LG",
            "cs.CL"
          ],
          "cluster_probability": 0.824915809103935
        },
        {
          "id": "2406.07515",
          "title": "Beyond Model Collapse: Scaling Up with Synthesized Data Requires\n  Verification",
          "summary": "Large Language Models (LLM) are increasingly trained on data generated by other LLM, either because generated text and images become part of the pre-training corpus, or because synthetized data is used as a replacement for expensive human-a…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2504.15208",
          "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
          "summary": "Why do larger language models generalize better? To investigate this question, we develop generalization bounds on the pretraining objective of large language models (LLMs) in the compute-optimal regime, as described by the Chinchilla scali…",
          "categories": [
            "cs.LG",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2503.00808",
          "title": "Predictive Data Selection: The Data That Predicts Is the Data That Teaches",
          "summary": "Language model pretraining involves training on extensive corpora, where data quality plays a pivotal role. In this work, we aim to directly estimate the contribution of data during pretraining and select pretraining data in an efficient ma…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 1,
      "size": 4,
      "mean_probability": 1.0,
      "top_categories": [
        "eess.AS",
        "cs.LG",
        "cs.CL",
        "cs.MM",
        "cs.SD"
      ],
      "representative_ids": [
        "2311.07919",
        "2407.10759",
        "2408.16532",
        "2412.19437"
      ],
      "samples": [
        {
          "id": "2311.07919",
          "title": "Qwen-Audio: Advancing Universal Audio Understanding via Unified\n  Large-Scale Audio-Language Models",
          "summary": "Recently, instruction-following audio-language models have received broad attention for audio interaction with humans. However, the absence of pre-trained audio models capable of handling diverse audio types and tasks has hindered progress…",
          "categories": [
            "eess.AS",
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2407.10759",
          "title": "Qwen2-Audio Technical Report",
          "summary": "We introduce the latest progress of Qwen-Audio, a large-scale audio-language model called Qwen2-Audio, which is capable of accepting various audio signal inputs and performing audio analysis or direct textual responses with regard to speech…",
          "categories": [
            "eess.AS",
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2408.16532",
          "title": "WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio\n  Language Modeling",
          "summary": "Language models have been effectively applied to modeling natural signals, such as images, video, speech, and audio. A crucial component of these models is the codec tokenizer, which compresses high-dimensional natural signals into lower-di…",
          "categories": [
            "eess.AS",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.SP"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2412.19437",
          "title": "DeepSeek-V3 Technical Report",
          "summary": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attentio…",
          "categories": [
            "cs.CL",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 2,
      "size": 21,
      "mean_probability": 0.5517408816801798,
      "top_categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.CV"
      ],
      "representative_ids": [
        "2504.03234",
        "2504.14047",
        "2504.15895",
        "2411.19865",
        "2504.16379"
      ],
      "samples": [
        {
          "id": "2504.03234",
          "title": "Think When You Need: Self-Adaptive Chain-of-Thought Learning",
          "summary": "Chain of Thought (CoT) reasoning enhances language models' performance but often leads to inefficient \"overthinking\" on simple problems. We identify that existing approaches directly penalizing reasoning length fail to account for varying p…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 0.5364801324580895
        },
        {
          "id": "2504.14047",
          "title": "Think Deep, Think Fast: Investigating Efficiency of Verifier-free\n  Inference-time-scaling Methods",
          "summary": "There is intense interest in investigating how inference time compute (ITC) (e.g. repeated sampling, refinements, etc) can improve large language model (LLM) capabilities. At the same time, recent breakthroughs in reasoning models, such as…",
          "categories": [
            "cs.AI"
          ],
          "cluster_probability": 0.2797163296059313
        },
        {
          "id": "2504.15895",
          "title": "Dynamic Early Exit in Reasoning Models",
          "summary": "Recent advances in large reasoning language models (LRLMs) rely on test-time scaling, which extends long chain-of-thought (CoT) generation to solve complex tasks. However, overthinking in long CoT not only slows down the efficiency of probl…",
          "categories": [
            "cs.CL",
            "cs.AI"
          ],
          "cluster_probability": 0.7228806311731063
        },
        {
          "id": "2411.19865",
          "title": "Reverse Thinking Makes LLMs Stronger Reasoners",
          "summary": "Reverse thinking plays a crucial role in human reasoning. Humans can reason not only from a problem to a solution but also in reverse, i.e., start from the solution and reason towards the problem. This often enhances overall reasoning perfo…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 0.49758375350973283
        },
        {
          "id": "2504.16379",
          "title": "SplitReason: Learning To Offload Reasoning",
          "summary": "Reasoning in large language models (LLMs) tends to produce substantially longer token generation sequences than simpler language modeling tasks. This extended generation length reflects the multi-step, compositional nature of reasoning and…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 3,
      "size": 6,
      "mean_probability": 0.8525613681356385,
      "top_categories": [
        "cs.CL",
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "cs.GT"
      ],
      "representative_ids": [
        "2411.07641",
        "2407.01082",
        "2210.15191",
        "2410.03968",
        "2502.03685"
      ],
      "samples": [
        {
          "id": "2411.07641",
          "title": "Top-$n\\sigma$: Not All Logits Are You Need",
          "summary": "Large language models (LLMs) typically employ greedy decoding or low-temperature sampling for reasoning tasks, reflecting a perceived trade-off between diversity and accuracy. We challenge this convention by introducing top-$n\\sigma$, a nov…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2407.01082",
          "title": "Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs",
          "summary": "Large Language Models (LLMs) generate text by sampling the next token from a probability distribution over the vocabulary at each decoding step. Popular sampling methods like top-p (nucleus sampling) often struggle to balance quality and di…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2210.15191",
          "title": "Truncation Sampling as Language Model Desmoothing",
          "summary": "Long samples of text from neural language models can be of poor quality. Truncation sampling algorithms--like top-$p$ or top-$k$ -- address this by setting some words' probabilities to zero at each step. This work provides framing for the a…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2410.03968",
          "title": "Decoding Game: On Minimax Optimality of Heuristic Text Generation Strategies",
          "summary": "Decoding strategies play a pivotal role in text generation for modern language models, yet a puzzling gap divides theory and practice. Surprisingly, strategies that should intuitively be optimal, such as Maximum a Posteriori (MAP), often pe…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "math.OC"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2502.03685",
          "title": "Controlled LLM Decoding via Discrete Auto-regressive Biasing",
          "summary": "Controlled text generation allows for enforcing user-defined constraints on large language model outputs, an increasingly important field as LLMs become more prevalent in everyday life. One common approach uses energy-based decoding, which…",
          "categories": [
            "cs.CL",
            "cs.LG",
            "stat.ML"
          ],
          "cluster_probability": 0.8020930128442132
        }
      ]
    },
    {
      "label": 4,
      "size": 8,
      "mean_probability": 0.8762849962355601,
      "top_categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.CY"
      ],
      "representative_ids": [
        "2502.04485",
        "2504.16078",
        "2402.02392",
        "2410.05434",
        "2410.13788"
      ],
      "samples": [
        {
          "id": "2502.04485",
          "title": "Active Task Disambiguation with LLMs",
          "summary": "Despite the impressive performance of large language models (LLMs) across various benchmarks, their ability to address ambiguously specified problems--frequent in real-world interactions--remains underexplored. To address this gap, we intro…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 0.8846205310088732
        },
        {
          "id": "2504.16078",
          "title": "LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making\n  Abilities",
          "summary": "The success of Large Language Models (LLMs) has sparked interest in various agentic applications. A key hypothesis is that LLMs, leveraging common sense and Chain-of-Thought (CoT) reasoning, can effectively explore and efficiently solve com…",
          "categories": [
            "cs.LG",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2402.02392",
          "title": "DeLLMa: Decision Making Under Uncertainty with Large Language Models",
          "summary": "The potential of large language models (LLMs) as decision support tools is increasingly being explored in fields such as business, engineering, and medicine, which often face challenging tasks of decision-making under uncertainty. In this p…",
          "categories": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 0.9364636289152648
        },
        {
          "id": "2410.05434",
          "title": "Better than Your Teacher: LLM Agents that learn from Privileged AI\n  Feedback",
          "summary": "While large language models (LLMs) show impressive decision-making abilities, current methods lack a mechanism for automatic self-improvement from errors during task execution. We propose LEAP, an iterative fine-tuning framework that contin…",
          "categories": [
            "cs.LG",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2410.13788",
          "title": "Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying\n  Questions",
          "summary": "Large language models (LLMs) must often respond to highly ambiguous user requests. In such cases, the LLM's best response may be to ask a clarifying question to elicit more information. Existing LLMs often respond by presupposing a single i…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 0.6412484339519331
        }
      ]
    },
    {
      "label": 5,
      "size": 4,
      "mean_probability": 1.0,
      "top_categories": [
        "cs.CL",
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "representative_ids": [
        "2406.12034",
        "2401.02412",
        "2501.06252",
        "2407.06089"
      ],
      "samples": [
        {
          "id": "2406.12034",
          "title": "Self-MoE: Towards Compositional Large Language Models with\n  Self-Specialized Experts",
          "summary": "We present Self-MoE, an approach that transforms a monolithic LLM into a compositional, modular system of self-specialized experts, named MiXSE (MiXture of Self-specialized Experts). Our approach leverages self-specialization, which constru…",
          "categories": [
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2401.02412",
          "title": "LLM Augmented LLMs: Expanding Capabilities through Composition",
          "summary": "Foundational models with billions of parameters which have been trained on large corpora of data have demonstrated non-trivial skills in a variety of domains. However, due to their monolithic structure, it is challenging and expensive to au…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2501.06252",
          "title": "Transformer-Squared: Self-adaptive LLMs",
          "summary": "Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce Transformer-Squared…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2407.06089",
          "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in\n  the Era of Large Language Models",
          "summary": "The remarkable success of Large Language Models (LLMs) has ushered natural language processing (NLP) research into a new era. Despite their diverse capabilities, LLMs trained on different corpora exhibit varying strengths and weaknesses, le…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 6,
      "size": 9,
      "mean_probability": 0.9142489557679772,
      "top_categories": [
        "cs.CL",
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "representative_ids": [
        "2410.09724",
        "2504.11337",
        "2409.08813",
        "2405.17931",
        "2409.17407"
      ],
      "samples": [
        {
          "id": "2410.09724",
          "title": "Taming Overconfidence in LLMs: Reward Calibration in RLHF",
          "summary": "Language model calibration refers to the alignment between the confidence of the model and the actual performance of its responses. While previous studies point out the overconfidence phenomenon in Large Language Models (LLMs) and show that…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 0.8070601504779485
        },
        {
          "id": "2504.11337",
          "title": "REWARD CONSISTENCY: Improving Multi-Objective Alignment from a\n  Data-Centric Perspective",
          "summary": "Multi-objective preference alignment in language models often encounters a challenging trade-off: optimizing for one human preference (e.g., helpfulness) frequently compromises others (e.g., harmlessness) due to the inherent conflicts betwe…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2409.08813",
          "title": "Your Weak LLM is Secretly a Strong Teacher for Alignment",
          "summary": "The burgeoning capabilities of large language models (LLMs) have underscored the need for alignment to ensure these models act in accordance with human values and intentions. Existing alignment frameworks present constraints either in the f…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 0.8070601504779485
        },
        {
          "id": "2405.17931",
          "title": "Online Merging Optimizers for Boosting Rewards and Mitigating Tax in\n  Alignment",
          "summary": "Effectively aligning Large Language Models (LLMs) with human-centric values while preventing the degradation of abilities acquired through Pre-training and Supervised Fine-tuning (SFT) poses a central challenge in Reinforcement Learning fro…",
          "categories": [
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2409.17407",
          "title": "Post-hoc Reward Calibration: A Case Study on Length Bias",
          "summary": "Reinforcement Learning from Human Feedback aligns the outputs of Large Language Models with human values and preferences. Central to this process is the reward model (RM), which translates human feedback into training signals for optimising…",
          "categories": [
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 7,
      "size": 5,
      "mean_probability": 0.950897806213433,
      "top_categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "math.DS"
      ],
      "representative_ids": [
        "2406.11014",
        "2406.15057",
        "2405.07987",
        "2305.06329",
        "2410.04814"
      ],
      "samples": [
        {
          "id": "2406.11014",
          "title": "Latent Communication in Artificial Neural Networks",
          "summary": "As NNs permeate various scientific and industrial domains, understanding the universality and reusability of their representations becomes crucial. At their core, these networks create intermediate neural representations, indicated as laten…",
          "categories": [
            "cs.LG",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2406.15057",
          "title": "Latent Space Translation via Inverse Relative Projection",
          "summary": "The emergence of similar representations between independently trained neural models has sparked significant interest in the representation learning community, leading to the development of various methods to obtain communication between la…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2405.07987",
          "title": "The Platonic Representation Hypothesis",
          "summary": "We argue that representations in AI models, particularly deep networks, are converging. First, we survey many examples of convergence in the literature: over time and across multiple domains, the ways by which different neural networks repr…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.NE"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2305.06329",
          "title": "Similarity of Neural Network Models: A Survey of Functional and Representational Measures",
          "summary": "Measuring similarity of neural networks to understand and improve their behavior has become an issue of great importance and research interest. In this survey, we provide a comprehensive overview of two complementary perspectives of measuri…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2410.04814",
          "title": "Learning Interpretable Hierarchical Dynamical Systems Models from Time\n  Series Data",
          "summary": "In science, we are often interested in obtaining a generative model of the underlying system dynamics from observed time series. While powerful methods for dynamical systems reconstruction (DSR) exist when data come from a single domain, ho…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "math.DS",
            "nlin.CD",
            "physics.data-an"
          ],
          "cluster_probability": 0.7544890310671655
        }
      ]
    },
    {
      "label": 8,
      "size": 4,
      "mean_probability": 1.0,
      "top_categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "representative_ids": [
        "2501.17039",
        "2404.04522",
        "2406.10251",
        "2501.15225"
      ],
      "samples": [
        {
          "id": "2501.17039",
          "title": "Enhanced Retrieval of Long Documents: Leveraging Fine-Grained Block\n  Representations with Large Language Models",
          "summary": "In recent years, large language models (LLMs) have demonstrated exceptional power in various domains, including information retrieval. Most of the previous practices involve leveraging these models to create a single embedding for each quer…",
          "categories": [
            "cs.IR"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2404.04522",
          "title": "Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text\n  Reranking with Large Language Models",
          "summary": "Parameter Efficient Fine-Tuning (PEFT) methods have been extensively utilized in Large Language Models (LLMs) to improve the down-streaming tasks without the cost of fine-tuing the whole LLMs. Recent studies have shown how to effectively us…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2406.10251",
          "title": "The Impact of Quantization on Retrieval-Augmented Generation: An\n  Analysis of Small LLMs",
          "summary": "Post-training quantization reduces the computational demand of Large Language Models (LLMs) but can weaken some of their capabilities. Since LLM abilities emerge with scale, smaller LLMs are more sensitive to quantization. In this paper, we…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2501.15225",
          "title": "SEAL: Scaling to Emphasize Attention for Long-Context Retrieval",
          "summary": "While many advanced LLMs are designed to handle long sequence data, we can still observe notable quality degradation even within the sequence limit. In this work, we introduce a novel approach called Scaling to Emphasize Attention for Long-…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 9,
      "size": 4,
      "mean_probability": 1.0,
      "top_categories": [
        "cs.CL",
        "cs.LG"
      ],
      "representative_ids": [
        "2408.03092",
        "2212.09849",
        "2406.11617",
        "2311.03099"
      ],
      "samples": [
        {
          "id": "2408.03092",
          "title": "Extend Model Merging from Fine-Tuned to Pre-Trained Large Language\n  Models via Weight Disentanglement",
          "summary": "Merging Large Language Models (LLMs) aims to amalgamate multiple homologous LLMs into one with all the capabilities. Ideally, any LLMs sharing the same backbone should be mergeable, irrespective of whether they are Fine-Tuned (FT) with mino…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2212.09849",
          "title": "Dataless Knowledge Fusion by Merging Weights of Language Models",
          "summary": "Fine-tuning pre-trained language models has become the prevalent paradigm for building downstream NLP models. Oftentimes fine-tuned models are readily available but their training data is not, due to data privacy or intellectual property co…",
          "categories": [
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2406.11617",
          "title": "DELLA-Merging: Reducing Interference in Model Merging through\n  Magnitude-Based Sampling",
          "summary": "With the proliferation of domain-specific models, model merging has emerged as a set of techniques that combine the capabilities of multiple models into one that can multitask without the cost of additional training. In this paper, we propo…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2311.03099",
          "title": "Language Models are Super Mario: Absorbing Abilities from Homologous\n  Models as a Free Lunch",
          "summary": "In this paper, we unveil that Language Models (LMs) can acquire new capabilities by assimilating parameters from homologous models without retraining or GPUs. We first introduce DARE to set most delta parameters (i.e., the disparity between…",
          "categories": [
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 10,
      "size": 23,
      "mean_probability": 0.8227393913035782,
      "top_categories": [
        "cs.LG",
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "representative_ids": [
        "2501.09522",
        "2310.02575",
        "2111.09832",
        "2501.00061",
        "2310.12808"
      ],
      "samples": [
        {
          "id": "2501.09522",
          "title": "Merging Models on the Fly Without Retraining: A Sequential Approach to\n  Scalable Continual Model Merging",
          "summary": "Deep model merging represents an emerging research direction that combines multiple fine-tuned models to harness their specialized capabilities across different tasks and domains. Current model merging techniques focus on merging all availa…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 0.748728303990054
        },
        {
          "id": "2310.02575",
          "title": "AdaMerging: Adaptive Model Merging for Multi-Task Learning",
          "summary": "Multi-task learning (MTL) aims to empower a model to tackle multiple tasks simultaneously. A recent development known as task arithmetic has revealed that several models, each fine-tuned for distinct tasks, can be directly merged into a sin…",
          "categories": [
            "cs.LG",
            "cs.CV"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2111.09832",
          "title": "Merging Models with Fisher-Weighted Averaging",
          "summary": "Averaging the parameters of models that have the same architecture and initialization can provide a means of combining their respective capabilities. In this paper, we take the perspective that this \"merging\" operation can be seen as choosi…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 0.600910632239966
        },
        {
          "id": "2501.00061",
          "title": "Training-free Heterogeneous Model Merging",
          "summary": "Model merging has attracted significant attention as a powerful paradigm for model reuse, facilitating the integration of task-specific models into a singular, versatile framework endowed with multifarious capabilities. Previous studies, pr…",
          "categories": [
            "cs.LG",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2310.12808",
          "title": "Model Merging by Uncertainty-Based Gradient Matching",
          "summary": "Models trained on different datasets can be merged by a weighted-averaging of their parameters, but why does it work and when can it fail? Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a ne…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 0.503858750110377
        }
      ]
    },
    {
      "label": 11,
      "size": 4,
      "mean_probability": 1.0,
      "top_categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "representative_ids": [
        "2410.14516",
        "2504.13644",
        "2407.12878",
        "2410.02064"
      ],
      "samples": [
        {
          "id": "2410.14516",
          "title": "Do LLMs \"know\" internally when they follow instructions?",
          "summary": "Instruction-following is crucial for building AI agents with large language models (LLMs), as these models must adhere strictly to user-provided constraints and guidelines. However, LLMs often fail to follow even simple and clear instructio…",
          "categories": [
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2504.13644",
          "title": "Exploring the Potential for Large Language Models to Demonstrate\n  Rational Probabilistic Beliefs",
          "summary": "Advances in the general capabilities of large language models (LLMs) have led to their use for information retrieval, and as components in automated decision systems. A faithful representation of probabilistic reasoning in these models may…",
          "categories": [
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2407.12878",
          "title": "Do LLMs have Consistent Values?",
          "summary": "Large Language Models (LLM) technology is constantly improving towards human-like dialogue. Values are a basic driving force underlying human behavior, but little research has been done to study the values exhibited in text generated by LLM…",
          "categories": [
            "cs.CL",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2410.02064",
          "title": "Inspection and Control of Self-Generated-Text Recognition Ability in\n  Llama3-8b-Instruct",
          "summary": "It has been reported that LLMs can recognize their own writing. As this has potential implications for AI safety, yet is relatively understudied, we investigate the phenomenon, seeking to establish whether it robustly occurs at the behavior…",
          "categories": [
            "cs.LG",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 12,
      "size": 9,
      "mean_probability": 0.989333875587085,
      "top_categories": [
        "cs.CL",
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "representative_ids": [
        "2504.16871",
        "2407.14985",
        "2504.12459",
        "2406.19501",
        "2401.06416"
      ],
      "samples": [
        {
          "id": "2504.16871",
          "title": "Exploring How LLMs Capture and Represent Domain-Specific Knowledge",
          "summary": "We study whether Large Language Models (LLMs) inherently capture domain-specific nuances in natural language. Our experiments probe the domain sensitivity of LLMs by examining their ability to distinguish queries from different domains usin…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 0.9630633346739904
        },
        {
          "id": "2407.14985",
          "title": "Generalization v.s. Memorization: Tracing Language Models' Capabilities\n  Back to Pretraining Data",
          "summary": "The impressive capabilities of large language models (LLMs) have sparked debate over whether these models genuinely generalize to unseen tasks or predominantly rely on memorizing vast amounts of pretraining data. To explore this issue, we i…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2504.12459",
          "title": "On Linear Representations and Pretraining Data Frequency in Language\n  Models",
          "summary": "Pretraining data has a direct impact on the behaviors and quality of language models (LMs), but we only understand the most basic principles of this relationship. While most work focuses on pretraining data's effect on downstream task behav…",
          "categories": [
            "cs.CL",
            "cs.AI"
          ],
          "cluster_probability": 0.9630633346739904
        },
        {
          "id": "2406.19501",
          "title": "Monitoring Latent World States in Language Models with Propositional\n  Probes",
          "summary": "Language models are susceptible to bias, sycophancy, backdoors, and other tendencies that lead to unfaithful responses to the input context. Interpreting internal states of language models could help monitor and correct unfaithful behavior.…",
          "categories": [
            "cs.CL",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2401.06416",
          "title": "Mission: Impossible Language Models",
          "summary": "Chomsky and others have very directly claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 13,
      "size": 10,
      "mean_probability": 0.7811650081662147,
      "top_categories": [
        "cs.LG",
        "cs.CL",
        "cs.AI",
        "stat.ML",
        "cs.DC"
      ],
      "representative_ids": [
        "2503.18216",
        "2410.14731",
        "2408.09632",
        "2502.13533",
        "2407.11239"
      ],
      "samples": [
        {
          "id": "2503.18216",
          "title": "Adaptive Rank Allocation: Speeding Up Modern Transformers with RaNA\n  Adapters",
          "summary": "Large Language Models (LLMs) are computationally intensive, particularly during inference. Neuron-adaptive techniques, which selectively activate neurons in Multi-Layer Perceptron (MLP) layers, offer some speedups but suffer from limitation…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 0.7652984741683921
        },
        {
          "id": "2410.14731",
          "title": "MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection",
          "summary": "KV cache has become a de facto technique for the inference of large language models (LLMs), where tensors of shape (layer number, head number, sequence length, feature dimension) are introduced to cache historical information for self-atten…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2408.09632",
          "title": "MoDeGPT: Modular Decomposition for Large Language Model Compression",
          "summary": "Large Language Models (LLMs) have reshaped the landscape of artificial intelligence by demonstrating exceptional performance across various tasks. However, substantial computational requirements make their deployment challenging on devices…",
          "categories": [
            "cs.LG",
            "cs.CL",
            "stat.ML"
          ],
          "cluster_probability": 0.8460166303914909
        },
        {
          "id": "2502.13533",
          "title": "Train Small, Infer Large: Memory-Efficient LoRA Training for Large\n  Language Models",
          "summary": "Large Language Models (LLMs) have significantly advanced natural language processing with exceptional task generalization capabilities. Low-Rank Adaption (LoRA) offers a cost-effective fine-tuning solution, freezing the original model param…",
          "categories": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
          ],
          "cluster_probability": 0.5711357585526486
        },
        {
          "id": "2407.11239",
          "title": "From Low Rank Gradient Subspace Stabilization to Low-Rank Weights: Observations, Theories, and Applications",
          "summary": "Large Language Models' (LLMs) weight matrices can often be expressed in low-rank form with potential to relax memory and compute resource requirements. Unlike prior efforts that focus on developing novel matrix decompositions, in this work…",
          "categories": [
            "cs.LG"
          ],
          "cluster_probability": 1.0
        }
      ]
    },
    {
      "label": 14,
      "size": 9,
      "mean_probability": 0.8586376325467161,
      "top_categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "representative_ids": [
        "2306.05176",
        "2305.13048",
        "2104.09864",
        "2006.04768",
        "2503.04355"
      ],
      "samples": [
        {
          "id": "2306.05176",
          "title": "RRWKV: Capturing Long-range Dependencies in RWKV",
          "summary": "Owing to the impressive dot-product attention, the Transformers have been the dominant architectures in various natural language processing (NLP) tasks. Recently, the Receptance Weighted Key Value (RWKV) architecture follows a non-transform…",
          "categories": [
            "cs.CL",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2305.13048",
          "title": "RWKV: Reinventing RNNs for the Transformer Era",
          "summary": "Transformers have revolutionized almost all natural language processing (NLP) tasks but suffer from memory and computational complexity that scales quadratically with sequence length. In contrast, recurrent neural networks (RNNs) exhibit li…",
          "categories": [
            "cs.CL",
            "cs.AI"
          ],
          "cluster_probability": 1.0
        },
        {
          "id": "2104.09864",
          "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding",
          "summary": "Position encoding recently has shown effective in the transformer architecture. It enables valuable supervision for dependency modeling between elements at different positions of the sequence. In this paper, we first investigate various met…",
          "categories": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
          ],
          "cluster_probability": 0.6740296995795514
        },
        {
          "id": "2006.04768",
          "title": "Linformer: Self-Attention with Linear Complexity",
          "summary": "Large transformer models have shown extraordinary success in achieving state-of-the-art results in many natural language processing applications. However, training and deploying these models can be prohibitively costly for long sequences, a…",
          "categories": [
            "cs.LG",
            "stat.ML"
          ],
          "cluster_probability": 0.9366332831781383
        },
        {
          "id": "2503.04355",
          "title": "Layer-Specific Scaling of Positional Encodings for Superior Long-Context\n  Modeling",
          "summary": "Although large language models (LLMs) have achieved significant progress in handling long-context inputs, they still suffer from the ``lost-in-the-middle'' problem, where crucial information in the middle of the context is often underrepres…",
          "categories": [
            "cs.CL"
          ],
          "cluster_probability": 0.7056919033875849
        }
      ]
    }
  ]
}